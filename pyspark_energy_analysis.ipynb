{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PySpark Data Engineering Portfolio: Energy Consumption Analysis\n",
                "\n",
                "This notebook demonstrates PySpark operations using publicly available datasets related to energy consumption in buildings and time series analysis.\n",
                "\n",
                "## Objectives:\n",
                "- Load energy consumption data from Open Power System Data.\n",
                "- Clean and transform data using PySpark.\n",
                "- Perform time series analysis.\n",
                "- Visualize energy consumption trends.\n",
                "- (Optional) Build a predictive model using PySpark MLlib.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install PySpark if not installed (Uncomment below)\n",
                "# !pip install pyspark\n",
                "\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.functions import col, avg, sum, count, to_timestamp, date_trunc\n",
                "import pandas as pd\n",
                "import plotly.express as px\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize PySpark session\n",
                "spark = SparkSession.builder.appName(\"EnergyConsumptionAnalysis\").getOrCreate()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fetch Energy Data from Open Power System Data\n",
                "We will use publicly available data from Open Power System Data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "def fetch_energy_data(url, save_path):\n",
                "    \"\"\"Downloads CSV data from Open Power System Data repository.\"\"\"\n",
                "    response = requests.get(url)\n",
                "    if response.status_code == 200:\n",
                "        with open(save_path, 'wb') as f:\n",
                "            f.write(response.content)\n",
                "        print(f\"Data saved to {save_path}\")\n",
                "    else:\n",
                "        print(\"Failed to download data\")\n",
                "\n",
                "# Example dataset (change URL as needed)\n",
                "dataset_url = \"https://data.open-power-system-data.org/time_series/2020-07-16/time_series_60min_singleindex.csv\"\n",
                "fetch_energy_data(dataset_url, \"energy_data.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset into PySpark DataFrame\n",
                "df = spark.read.csv(\"energy_data.csv\", header=True, inferSchema=True)\n",
                "df.printSchema()\n",
                "df.show(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Cleaning\n",
                "We will handle missing values and ensure proper timestamp formats."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values by filling with mean\n",
                "df = df.fillna({\"energy_consumption\": df.agg({\"energy_consumption\": \"mean\"}).collect()[0][0]})\n",
                "\n",
                "# Convert timestamp column\n",
                "df = df.withColumn(\"timestamp_column\", to_timestamp(col(\"utc_timestamp\")))\n",
                "df.show(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Time Series Analysis\n",
                "We aggregate energy consumption data by day."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "daily_consumption = df.withColumn(\"date\", date_trunc(\"day\", col(\"timestamp_column\")))\\\n",
                "                   .groupBy(\"date\")\\\n",
                "                   .agg(sum(\"energy_consumption\").alias(\"total_daily_consumption\"))\n",
                "daily_consumption.show(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization\n",
                "We use Plotly to visualize daily energy consumption trends."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "daily_pd = daily_consumption.toPandas()\n",
                "fig = px.line(daily_pd, x=\"date\", y=\"total_daily_consumption\", title=\"Daily Energy Consumption\")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "- We successfully loaded and processed energy consumption data using PySpark.\n",
                "- We aggregated data by day to analyze trends.\n",
                "- Interactive visualizations were generated using Plotly.\n",
                "\n",
                "**Next Steps:**\n",
                "- Implement a predictive model using PySpark MLlib.\n",
                "- Perform anomaly detection in energy consumption patterns.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}